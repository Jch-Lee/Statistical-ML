{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# 1. 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. 데이터 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # EfficientNet-B0는 224x224 입력 크기 사용\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))  # CIFAR-10의 정규화 값 사용\n",
    "])\n",
    "\n",
    "# 3. 사용자 데이터셋 불러오기\n",
    "trainset_path = 'C:/Users/USER/Desktop/Semester2/train_data'\n",
    "user_dataset = datasets.ImageFolder(root=trainset_path, transform=transform)\n",
    "\n",
    "# 4. CIFAR-10 데이터셋 불러오기 (훈련 데이터만 사용)\n",
    "cifar10_dataset = datasets.CIFAR10(root=\"C:/Users/USER/Desktop/Semester2/CIFAR10\", train=True, download=False, transform=transform)\n",
    "\n",
    "# 5. 사용자 데이터셋과 CIFAR-10 데이터셋 통합\n",
    "combined_dataset = ConcatDataset([user_dataset, cifar10_dataset])\n",
    "combined_labels = np.concatenate((np.array([label for _, label in user_dataset.samples]),\n",
    "                                  np.array(cifar10_dataset.targets)))\n",
    "\n",
    "# 6. Augmentation 방법 설정\n",
    "# aug1: Horizontal Flip + Rotation + Resized Crop\n",
    "aug1_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "# aug2: Horizontal Flip + Rotation + Color Jitter\n",
    "aug2_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomHorizontalFlip(p=0.7),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, hue=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "# 7. Augmented CIFAR-10 데이터셋 생성\n",
    "aug1_cifar10_dataset = datasets.CIFAR10(root=\"C:/Users/USER/Desktop/Semester2/CIFAR10\", train=True, download=False, transform=aug1_transform)\n",
    "aug2_cifar10_dataset = datasets.CIFAR10(root=\"C:/Users/USER/Desktop/Semester2/CIFAR10\", train=True, download=False, transform=aug2_transform)\n",
    "\n",
    "# 각 Augmented Dataset에서 10,000개씩 샘플링\n",
    "aug1_indices = random.sample(range(len(aug1_cifar10_dataset)), 15000)\n",
    "aug2_indices = random.sample(range(len(aug2_cifar10_dataset)), 15000)\n",
    "aug1_subset = Subset(aug1_cifar10_dataset, aug1_indices)\n",
    "aug2_subset = Subset(aug2_cifar10_dataset, aug2_indices)\n",
    "\n",
    "# 최종 데이터셋 구성: user_data 4000 + CIFAR10 50000 + aug1 10000 + aug2 10000\n",
    "final_combined_dataset = ConcatDataset([combined_dataset, aug1_subset, aug2_subset])\n",
    "\n",
    "# 최종 데이터셋의 레이블 배열 생성\n",
    "aug1_labels = np.array([aug1_cifar10_dataset[i][1] for i in aug1_indices])\n",
    "aug2_labels = np.array([aug2_cifar10_dataset[i][1] for i in aug2_indices])\n",
    "final_combined_labels = np.concatenate((combined_labels, aug1_labels, aug2_labels))\n",
    "\n",
    "print(f\"Total number of samples in final dataset: {len(final_combined_dataset)}\")\n",
    "\n",
    "# 8. 데이터셋을 학습 및 검증 세트로 나누기 (Stratified Split)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(final_combined_labels)),\n",
    "    test_size=0.2,  # 전체 데이터의 1/5을 검증 데이터로 사용\n",
    "    stratify=final_combined_labels,  # 각 클래스의 비율을 유지하며 분할\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_subset = Subset(final_combined_dataset, train_idx)\n",
    "val_subset = Subset(final_combined_dataset, val_idx)\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=1)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "# 9. 학습 및 평가 루프 (K-Fold 루프 제거)\n",
    "num_epochs = 30\n",
    "train_accuracies, val_accuracies = [], []  # 전체 에포크의 정확도 저장\n",
    "\n",
    "# EfficientNet-B0 모델 설정 (사전 학습 없음)\n",
    "model3 = models.efficientnet_b0(pretrained=False)\n",
    "num_classes = 10  # CIFAR-10의 클래스 수 (사용자 데이터셋도 동일한 클래스 수로 가정)\n",
    "model3.classifier[1] = nn.Linear(model3.classifier[1].in_features, num_classes)\n",
    "model3 = model3.to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 및 검증\n",
    "for epoch in range(num_epochs):\n",
    "    # === 학습 ===\n",
    "    model3.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model3(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # 학습 정확도 기록\n",
    "    train_acc = 100. * correct_train / total_train\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # === 검증 ===\n",
    "    model3.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model3(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # 검증 정확도 기록\n",
    "    val_acc = 100. * correct_val / total_val\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# 최종 평균 검증 정확도 출력\n",
    "print(\"\\n=== 최종 검증 정확도 ===\")\n",
    "print(f\"Validation Accuracy: {np.mean(val_accuracies):.2f}%\")\n",
    "\n",
    "# 정확도 시각화\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Accuracy', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Validation Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
