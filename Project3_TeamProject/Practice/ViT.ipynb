{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.8896\n",
      "Epoch [2/3], Loss: 0.9446\n",
      "Epoch [3/3], Loss: 0.4807\n",
      "Fold 1 Accuracy: 94.92%\n",
      "Fold 2 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.8616\n",
      "Epoch [2/3], Loss: 0.9122\n",
      "Epoch [3/3], Loss: 0.4578\n",
      "Fold 2 Accuracy: 95.18%\n",
      "Fold 3 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.8768\n",
      "Epoch [2/3], Loss: 0.9296\n",
      "Epoch [3/3], Loss: 0.4778\n",
      "Fold 3 Accuracy: 94.26%\n",
      "Fold 4 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.8307\n",
      "Epoch [2/3], Loss: 0.8999\n",
      "Epoch [3/3], Loss: 0.4703\n",
      "Fold 4 Accuracy: 97.00%\n",
      "Fold 5 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.8618\n",
      "Epoch [2/3], Loss: 0.9069\n",
      "Epoch [3/3], Loss: 0.4677\n",
      "Fold 5 Accuracy: 95.69%\n",
      "Average 5-Fold Accuracy: 95.41%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. 장치 설정 (GPU 사용 가능 시 GPU 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. 클래스 수 정의 (사용자 정의 trainset의 클래스 수에 맞게 설정)\n",
    "num_classes = 10  # 예: 클래스가 10개인 데이터셋을 가정\n",
    "\n",
    "# 3. ViT 전처리기 설정\n",
    "#    Hugging Face에서 제공하는 ViT 전처리기를 사용하여 데이터 전처리 기준(mean, std 등)을 자동으로 불러옴\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# 4. 데이터 변환 설정\n",
    "#    모든 이미지를 224x224 크기로 조정하고, ViT 전처리 기준에 맞춰 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "])\n",
    "\n",
    "# 5. 사용자 정의 데이터셋 불러오기\n",
    "#    새로운 경로 설정 및 전처리를 적용하여 데이터셋을 생성\n",
    "trainset_path = 'C:/Users/jongcheol/OneDrive/바탕 화면/Semester2/train_data'\n",
    "trainset = datasets.ImageFolder(root=trainset_path, transform=transform)\n",
    "labels = np.array([label for _, label in trainset.imgs])  # 각 이미지의 레이블을 numpy 배열로 추출 (StratifiedKFold에 필요)\n",
    "\n",
    "# 6. 5-Fold Cross Validation 설정\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 5개 폴드로 데이터셋을 나누고, 레이블 분포가 비슷하도록 Stratified KFold 사용\n",
    "fold_accuracies = []  # 각 폴드의 정확도를 저장할 리스트\n",
    "\n",
    "# 7. Cross Validation 학습 및 평가\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.zeros(len(labels)), labels)):\n",
    "    print(f\"Fold {fold + 1} 시작\")\n",
    "\n",
    "    # Fold별 데이터셋 생성\n",
    "    train_subset = Subset(trainset, train_idx)\n",
    "    val_subset = Subset(trainset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    # 8. Vision Transformer 모델 초기화\n",
    "    #    Hugging Face의 ViT 모델을 불러와 num_classes에 맞게 최종 분류 계층을 설정\n",
    "    model = ViTForImageClassification.from_pretrained(\n",
    "        'google/vit-base-patch16-224-in21k',\n",
    "        num_labels=num_classes\n",
    "    ).to(device)\n",
    "\n",
    "    # 9. 손실 함수 및 옵티마이저 설정\n",
    "    #    다중 클래스 분류를 위한 CrossEntropyLoss와 Adam 옵티마이저 사용\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "    # 10. 학습 루프\n",
    "    num_epochs = 3  # 예시로 3에포크 (실제 학습에서는 더 큰 값으로 설정 가능)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 학습 모드 설정\n",
    "        running_loss = 0.0  # 에포크 손실 초기화\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # 데이터와 레이블을 장치로 이동\n",
    "\n",
    "            # 순전파, 손실 계산, 역전파, 옵티마이저 업데이트\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits  # 모델 예측\n",
    "            loss = criterion(outputs, labels)  # 손실 계산\n",
    "            loss.backward()  # 역전파\n",
    "            optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "            running_loss += loss.item()  # 배치 손실을 누적하여 에포크 손실 계산\n",
    "\n",
    "        # 에포크 종료 후 평균 손실 출력\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # 11. 검증 루프\n",
    "    model.eval()  # 평가 모드 설정\n",
    "    val_labels = []  # 실제 레이블을 저장할 리스트\n",
    "    val_preds = []  # 예측 레이블을 저장할 리스트\n",
    "\n",
    "    with torch.no_grad():  # 평가 시에는 기울기 계산을 하지 않음\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).logits  # 모델 예측\n",
    "            _, preds = torch.max(outputs, 1)  # 예측 레이블 추출\n",
    "            val_labels.extend(labels.cpu().numpy())  # 실제 레이블 추가\n",
    "            val_preds.extend(preds.cpu().numpy())  # 예측 레이블 추가\n",
    "\n",
    "    # 12. 폴드 정확도 계산 및 저장\n",
    "    fold_accuracy = accuracy_score(val_labels, val_preds)  # 정확도 계산\n",
    "    fold_accuracies.append(fold_accuracy)  # 폴드별 정확도 저장\n",
    "    print(f\"Fold {fold + 1} Accuracy: {fold_accuracy * 100:.2f}%\")\n",
    "\n",
    "# 13. 5-Fold 평균 정확도 출력\n",
    "print(f\"Average 5-Fold Accuracy: {np.mean(fold_accuracies) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# 테스트 데이터 경로 설정\n",
    "test_data_path = 'C:/Users/jongcheol/OneDrive/바탕 화면/Semester2/test_data'\n",
    "\n",
    "# 테스트 데이터 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 테스트 데이터셋 클래스 정의 (이미지 폴더 구조가 없을 경우)\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.image_files = sorted([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.folder_path, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # RGB로 변환 (흑백 방지)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, img_name\n",
    "\n",
    "# 테스트 데이터셋 및 DataLoader 생성\n",
    "test_dataset = TestDataset(test_data_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# train 데이터셋 로드하여 클래스명-인덱스 매핑 가져오기\n",
    "idx_to_class = {v: k for k, v in trainset.class_to_idx.items()}  # 인덱스 -> 클래스명 매핑 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과가 'ViT_predictions.csv' 파일에 클래스명으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "# 테스트 데이터 예측 수행\n",
    "with torch.no_grad():\n",
    "    for images, img_names in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images).logits\n",
    "        _, preds = torch.max(outputs, 1)  # 예측된 클래스 인덱스 추출\n",
    "\n",
    "        # 결과 저장 (이미지 파일명과 예측된 클래스명)\n",
    "        for img_name, pred in zip(img_names, preds.cpu().numpy()):\n",
    "            class_name = idx_to_class[pred]  # 예측된 인덱스를 클래스명으로 변환\n",
    "            predictions.append((img_name, class_name))\n",
    "\n",
    "# 예측 결과를 DataFrame으로 변환\n",
    "pred_df = pd.DataFrame(predictions, columns=[\"filename\", \"label\"])\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "output_path = \"ViT_predictions.csv\"\n",
    "pred_df.to_csv(output_path, index=False)\n",
    "print(f\"예측 결과가 '{output_path}' 파일에 클래스명으로 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
