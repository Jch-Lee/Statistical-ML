{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69000\n",
      "69000\n",
      "\n",
      "=== Fold 1 시작 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold [1], Epoch [1/30], Train Acc: 42.82%, Val Acc: 59.53%\n",
      "Fold [1], Epoch [2/30], Train Acc: 63.39%, Val Acc: 70.23%\n",
      "Fold [1], Epoch [3/30], Train Acc: 72.92%, Val Acc: 76.70%\n",
      "Fold [1], Epoch [4/30], Train Acc: 77.22%, Val Acc: 80.08%\n",
      "Fold [1], Epoch [5/30], Train Acc: 80.68%, Val Acc: 82.78%\n",
      "Fold [1], Epoch [6/30], Train Acc: 82.89%, Val Acc: 84.36%\n",
      "Fold [1], Epoch [7/30], Train Acc: 84.70%, Val Acc: 84.98%\n",
      "Fold [1], Epoch [8/30], Train Acc: 86.39%, Val Acc: 85.76%\n",
      "Fold [1], Epoch [9/30], Train Acc: 87.64%, Val Acc: 86.26%\n",
      "Fold [1], Epoch [10/30], Train Acc: 88.92%, Val Acc: 86.63%\n",
      "Fold [1], Epoch [11/30], Train Acc: 89.72%, Val Acc: 87.30%\n",
      "Fold [1], Epoch [12/30], Train Acc: 90.57%, Val Acc: 88.24%\n",
      "Fold [1], Epoch [13/30], Train Acc: 91.40%, Val Acc: 87.95%\n",
      "Fold [1], Epoch [14/30], Train Acc: 91.93%, Val Acc: 88.36%\n",
      "Fold [1], Epoch [15/30], Train Acc: 92.55%, Val Acc: 88.12%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset, SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# 1. 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. 데이터 전처리 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # EfficientNet-B0는 224x224 입력 크기 사용\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))  # CIFAR-10의 정규화 값 사용\n",
    "])\n",
    "\n",
    "# 3. 사용자 데이터셋 불러오기\n",
    "trainset_path = 'C:/Users/USER/Desktop/Semester2/train_data'\n",
    "user_dataset = datasets.ImageFolder(root=trainset_path, transform=transform)\n",
    "\n",
    "# 4. CIFAR-10 데이터셋 불러오기 (훈련 데이터만 사용)\n",
    "cifar10_dataset = datasets.CIFAR10(root=\"C:/Users/USER/Desktop/Semester2/CIFAR10\", train=True, download=False, transform=transform)\n",
    "\n",
    "# 5. 사용자 데이터셋과 CIFAR-10 데이터셋 통합\n",
    "combined_dataset = ConcatDataset([user_dataset, cifar10_dataset])\n",
    "combined_labels = np.concatenate((np.array([label for _, label in user_dataset.samples]),\n",
    "                                  np.array(cifar10_dataset.targets)))\n",
    "\n",
    "# 6. Augmentation 추가\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "augmented_user_dataset = datasets.ImageFolder(root=trainset_path, transform=augmentation_transform)\n",
    "augmented_cifar10_dataset = datasets.CIFAR10(root=\"C:/Users/USER/Desktop/Semester2/CIFAR10\", train=True, download=False, transform=augmentation_transform)\n",
    "augmented_combined_dataset = ConcatDataset([augmented_user_dataset, augmented_cifar10_dataset])\n",
    "\n",
    "# Augmented dataset에서 15,000개 샘플 무작위 추출\n",
    "augmented_indices = random.sample(range(len(augmented_combined_dataset)), 15000)\n",
    "augmented_subset = Subset(augmented_combined_dataset, augmented_indices)\n",
    "\n",
    "# 원본 combined_dataset과 augmented_subset 합치기\n",
    "final_combined_dataset = ConcatDataset([combined_dataset, augmented_subset])\n",
    "\n",
    "# final_combined_dataset의 레이블 배열 생성\n",
    "augmented_labels = np.array([augmented_combined_dataset[i][1] for i in augmented_indices])\n",
    "final_combined_labels = np.concatenate((combined_labels, augmented_labels))\n",
    "\n",
    "print(len(final_combined_dataset))\n",
    "print(len(final_combined_labels))\n",
    "\n",
    "# 7. K-Fold Cross Validation 설정\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "fold_accuracies = []  # 각 폴드의 검증 정확도 저장\n",
    "train_accuracies, val_accuracies = [], []  # 전체 에포크의 정확도 저장\n",
    "\n",
    "# 8. Cross Validation 학습 및 평가\n",
    "num_epochs = 30\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(np.zeros(len(final_combined_labels)), final_combined_labels)):\n",
    "    print(f\"\\n=== Fold {fold + 1} 시작 ===\")\n",
    "\n",
    "    # Fold별 데이터셋 분리\n",
    "    train_subset = Subset(final_combined_dataset, train_idx)\n",
    "    val_subset = Subset(final_combined_dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=1)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "    # EfficientNet-B0 모델 설정 (사전 학습 없음)\n",
    "    model = models.efficientnet_b0(pretrained=False)\n",
    "    num_classes = 10  # CIFAR-10의 클래스 수 (사용자 데이터셋도 동일한 클래스 수로 가정)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 손실 함수 및 옵티마이저 설정\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Fold 학습 및 검증\n",
    "    fold_train_acc, fold_val_acc = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        # === 학습 ===\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # 학습 정확도 기록\n",
    "        train_acc = 100. * correct_train / total_train\n",
    "        fold_train_acc.append(train_acc)\n",
    "\n",
    "        # === 검증 ===\n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # 검증 정확도 기록\n",
    "        val_acc = 100. * correct_val / total_val\n",
    "        fold_val_acc.append(val_acc)\n",
    "\n",
    "        print(f\"Fold [{fold + 1}], Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # 각 폴드별 학습 및 검증 정확도 기록\n",
    "    train_accuracies.append(fold_train_acc)\n",
    "    val_accuracies.append(fold_val_acc)\n",
    "    fold_accuracies.append(val_acc)  # 마지막 에포크의 검증 정확도 저장\n",
    "\n",
    "# 9. 최종 K-Fold 평균 정확도 출력\n",
    "print(\"\\n=== 최종 K-Fold 평균 정확도 ===\")\n",
    "print(f\"Average {k}-Fold Accuracy: {np.mean(fold_accuracies):.2f}%\")\n",
    "\n",
    "# 10. 정확도 시각화\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 폴드별 학습 및 검증 정확도 변화 시각화\n",
    "for i in range(k):\n",
    "    plt.plot(epochs_range, train_accuracies[i], label=f'Fold {i+1} Train Acc')\n",
    "    plt.plot(epochs_range, val_accuracies[i], label=f'Fold {i+1} Val Acc', linestyle='--')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Validation Accuracy per Fold')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# 총 데이터셋 결합 (기존 사용자 데이터셋 + CIFAR-10 데이터셋 + Augmentation 적용된 데이터셋)\n",
    "combined_dataset2 = final_combined_dataset\n",
    "combined_labels2 = final_combined_labels\n",
    "\n",
    "# 4. CutMix를 적용하는 함수\n",
    "def cutmix_data(input, target, beta=1.0):\n",
    "    lam = np.random.beta(beta, beta)\n",
    "    rand_index = torch.randperm(input.size()[0]).to(device)\n",
    "    target_a = target\n",
    "    target_b = target[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n",
    "    input[:, :, bbx1:bbx2, bby1:bby2] = input[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size(-1) * input.size(-2)))\n",
    "    return input, target_a, target_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# 5. K-Fold Cross Validation 설정\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "cutmix_prob = 0.2\n",
    "train_accuracies2, val_accuracies2 = [], []\n",
    "\n",
    "# 6. 모델 학습 및 검증 루프 (model2 사용)\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(combined_labels2)), combined_labels2)):\n",
    "    print(f\"\\n=== Fold {fold + 1}/{k} ===\")\n",
    "    train_subset = Subset(combined_dataset2, train_idx)\n",
    "    val_subset = Subset(combined_dataset2, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model2 = models.efficientnet_b0(pretrained=False)\n",
    "    model2.classifier[1] = nn.Linear(model2.classifier[1].in_features, 10)\n",
    "    model2 = model2.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model2.parameters(), lr=0.001)  # 학습률 고정\n",
    "\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model2.train()\n",
    "        correct_train, total_train = 0, 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # CutMix 적용 여부 결정\n",
    "            r = np.random.rand(1)\n",
    "            if r < cutmix_prob:\n",
    "                inputs, target_a, target_b, lam = cutmix_data(inputs, targets)\n",
    "                outputs = model2(inputs)\n",
    "                loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "            else:\n",
    "                outputs = model2(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct_train += preds.eq(targets).sum().item()\n",
    "            total_train += targets.size(0)\n",
    "\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "        # 검증\n",
    "        model2.eval()\n",
    "        correct_val, total_val = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model2(inputs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct_val += preds.eq(targets).sum().item()\n",
    "                total_val += targets.size(0)\n",
    "\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    train_accuracies2.append(train_acc_history)\n",
    "    val_accuracies2.append(val_acc_history)\n",
    "\n",
    "# 7. 학습 및 검증 정확도 시각화\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(k):\n",
    "    plt.plot(epochs_range, train_accuracies2[i], label=f'Fold {i+1} Train Acc')\n",
    "    plt.plot(epochs_range, val_accuracies2[i], label=f'Fold {i+1} Val Acc', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Validation Accuracy per Fold (CutMix 적용)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
