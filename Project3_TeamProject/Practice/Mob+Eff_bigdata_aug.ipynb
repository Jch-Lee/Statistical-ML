{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74000\n",
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Train Acc: 44.64%, Val Acc: 58.27%, LR: 0.000815\n",
      "Epoch [2/25], Train Acc: 62.34%, Val Acc: 67.81%, LR: 0.001988\n",
      "Epoch [3/25], Train Acc: 68.61%, Val Acc: 71.96%, LR: 0.003717\n",
      "Epoch [4/25], Train Acc: 71.16%, Val Acc: 75.63%, LR: 0.005702\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. 데이터 전처리 설정\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "augment1 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "augment2 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomHorizontalFlip(p=0.7),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "# 3. 데이터셋 로드\n",
    "trainset_path = \"C:/Users/USER/Desktop/Semester2/train_data\"\n",
    "user_dataset = datasets.ImageFolder(root=trainset_path, transform=basic_transform)\n",
    "\n",
    "cifar10 = datasets.CIFAR10(root=\"C:/Users/USER/Desktop/Semester2/CIFAR10\", train=True, download=False, transform=basic_transform)\n",
    "cifar10_dataset1 = datasets.CIFAR10(root=\"C:/Users/USER/Desktop/Semester2/CIFAR10\", train=True, download=False, transform=augment1)\n",
    "cifar10_dataset2 = datasets.CIFAR10(root=\"C:/Users/USER/Desktop/Semester2/CIFAR10\", train=True, download=False, transform=augment2)\n",
    "\n",
    "# 4. 랜덤하게 10,000장씩 선택\n",
    "num_samples = 10000\n",
    "indices1 = np.random.choice(len(cifar10_dataset1), num_samples, replace=False)\n",
    "indices2 = np.random.choice(len(cifar10_dataset2), num_samples, replace=False)\n",
    "cifar10_dataset1 = Subset(cifar10_dataset1, indices1)\n",
    "cifar10_dataset2 = Subset(cifar10_dataset2, indices2)\n",
    "\n",
    "# 5. 데이터셋 결합\n",
    "combined_dataset = ConcatDataset([user_dataset, cifar10, cifar10_dataset1, cifar10_dataset2])\n",
    "combined_labels = np.concatenate((np.array([label for _, label in user_dataset.samples]),\n",
    "                                  np.array(cifar10.targets),\n",
    "                                  np.array(cifar10.targets)[indices1],  # 선택된 인덱스의 라벨\n",
    "                                  np.array(cifar10.targets)[indices2]))\n",
    "\n",
    "print(len(combined_dataset))\n",
    "\n",
    "# 6. CutMix를 적용하는 함수\n",
    "def cutmix_data(input, target, beta=1.0):\n",
    "    lam = np.random.beta(beta, beta)\n",
    "    rand_index = torch.randperm(input.size()[0]).to(device)\n",
    "    target_a = target\n",
    "    target_b = target[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n",
    "    input[:, :, bbx1:bbx2, bby1:bby2] = input[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size(-1) * input.size(-2)))\n",
    "    return input, target_a, target_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# 7. K-Fold Cross Validation 설정\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "num_epochs = 25\n",
    "batch_size = 32\n",
    "cutmix_prob = 0.1\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# 8. 모델 학습 및 검증 루프\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(combined_labels)), combined_labels)):\n",
    "    print(f\"\\n=== Fold {fold + 1}/{k} ===\")\n",
    "    train_subset = Subset(combined_dataset, train_idx)\n",
    "    val_subset = Subset(combined_dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = models.efficientnet_b0(pretrained=False)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.003)  # 초기 학습률을 약간 높게 설정\n",
    "\n",
    "    # 학습률 스케줄러 설정 (OneCycleLR)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        correct_train, total_train = 0, 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # CutMix 적용 여부 결정\n",
    "            r = np.random.rand(1)\n",
    "            if r < cutmix_prob:\n",
    "                inputs, target_a, target_b, lam = cutmix_data(inputs, targets)\n",
    "                outputs = model(inputs)\n",
    "                loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # 학습률 업데이트\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct_train += preds.eq(targets).sum().item()\n",
    "            total_train += targets.size(0)\n",
    "\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        correct_val, total_val = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct_val += preds.eq(targets).sum().item()\n",
    "                total_val += targets.size(0)\n",
    "\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "    train_accuracies.append(train_acc_history)\n",
    "    val_accuracies.append(val_acc_history)\n",
    "\n",
    "# 9. 학습 및 검증 정확도 시각화\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(k):\n",
    "    plt.plot(epochs_range, train_accuracies[i], label=f'Fold {i+1} Train Acc')\n",
    "    plt.plot(epochs_range, val_accuracies[i], label=f'Fold {i+1} Val Acc', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Validation Accuracy per Fold')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# 1. 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. 테스트 데이터 전처리 설정\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "# 3. 테스트 데이터셋 로드\n",
    "test_data_path = \"C:/Users/USER/Desktop/Semester2/test_data\"\n",
    "\n",
    "# test_data 폴더에 있는 파일 이름을 읽어와서 오름차순으로 정렬\n",
    "test_filenames = sorted([f for f in os.listdir(test_data_path) if f.endswith('.png')])\n",
    "\n",
    "# 클래스 이름 리스트 (훈련 시 사용한 순서와 동일하게 설정)\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# 4. 모델 불러오기 (훈련된 모델을 불러와야 함)\n",
    "# 모델이 저장된 경로에서 checkpoint를 로드합니다.\n",
    "model = models.efficientnet_b0(pretrained=False)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))  # 클래스 수에 맞게 조정\n",
    "model.load_state_dict(torch.load(\"path_to_your_trained_model.pth\"))  # 저장된 모델 경로\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 5. 예측 및 결과 저장\n",
    "results = []\n",
    "\n",
    "# 각 이미지를 불러와서 모델로 예측 수행\n",
    "with torch.no_grad():\n",
    "    for filename in test_filenames:\n",
    "        # 이미지 불러오기 및 전처리\n",
    "        img_path = os.path.join(test_data_path, filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = test_transform(image)\n",
    "        image = image.unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "\n",
    "        # 모델 예측 수행\n",
    "        output = model(image)\n",
    "        _, predicted = output.max(1)\n",
    "        label = class_names[predicted.item()]  # 예측된 클래스의 이름을 가져옴\n",
    "\n",
    "        # 결과 리스트에 추가\n",
    "        results.append({\"filename\": filename, \"label\": label})\n",
    "\n",
    "# 6. 결과를 DataFrame으로 변환 후 CSV 파일로 저장\n",
    "df = pd.DataFrame(results)\n",
    "output_csv_path = \"C:/Users/USER/Desktop/Semester2/test_pred.csv\"\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"예측 결과가 {output_csv_path}에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
