{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jongcheol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jongcheol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 120\u001b[0m\n\u001b[0;32m    117\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    119\u001b[0m     _, preds \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m     correct_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     total_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    123\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m correct_train \u001b[38;5;241m/\u001b[39m total_train\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. 데이터 전처리 설정\n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "augment1 = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "augment2 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomHorizontalFlip(p=0.7),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "# 3. 데이터셋 로드 및 결합\n",
    "trainset_path = \"C:/Users/jongcheol/OneDrive/바탕 화면/Semester2/train_data\"\n",
    "user_dataset = datasets.ImageFolder(root=trainset_path, transform=basic_transform)\n",
    "\n",
    "cifar10 = datasets.CIFAR10(root=\"C:/Users/jongcheol/OneDrive/바탕 화면/Semester2/CIFAR10\", train=True, download=False, transform=basic_transform)\n",
    "cifar10_dataset1 = datasets.CIFAR10(root=\"C:/Users/jongcheol/OneDrive/바탕 화면/Semester2/CIFAR10\", train=True, download=False, transform=augment1)\n",
    "cifar10_dataset2 = datasets.CIFAR10(root=\"C:/Users/jongcheol/OneDrive/바탕 화면/Semester2/CIFAR10\", train=True, download=False, transform=augment2)\n",
    "\n",
    "combined_dataset = ConcatDataset([user_dataset, cifar10, cifar10_dataset1, cifar10_dataset2])\n",
    "combined_labels = np.concatenate((np.array([label for _, label in user_dataset.samples]),\n",
    "                                  np.array(cifar10.targets),\n",
    "                                  np.array(cifar10_dataset1.targets),\n",
    "                                  np.array(cifar10_dataset2.targets)))\n",
    "\n",
    "# 4. CutMix를 적용하는 함수\n",
    "def cutmix_data(input, target, beta=1.0):\n",
    "    lam = np.random.beta(beta, beta)\n",
    "    rand_index = torch.randperm(input.size()[0]).to(device)\n",
    "    target_a = target\n",
    "    target_b = target[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n",
    "    input[:, :, bbx1:bbx2, bby1:bby2] = input[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size(-1) * input.size(-2)))\n",
    "    return input, target_a, target_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "# 5. K-Fold Cross Validation 설정\n",
    "k = 5\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "cutmix_prob = 0.5\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# 6. 모델 학습 및 검증 루프\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(combined_labels)), combined_labels)):\n",
    "    print(f\"\\n=== Fold {fold + 1}/{k} ===\")\n",
    "    train_subset = Subset(combined_dataset, train_idx)\n",
    "    val_subset = Subset(combined_dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = models.efficientnet_b0(pretrained=False)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        correct_train, total_train = 0, 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # CutMix 적용 여부 결정\n",
    "            r = np.random.rand(1)\n",
    "            if r < cutmix_prob:\n",
    "                inputs, target_a, target_b, lam = cutmix_data(inputs, targets)\n",
    "                outputs = model(inputs)\n",
    "                loss = lam * criterion(outputs, target_a) + (1 - lam) * criterion(outputs, target_b)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct_train += preds.eq(targets).sum().item()\n",
    "            total_train += targets.size(0)\n",
    "\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_acc_history.append(train_acc)\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        correct_val, total_val = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct_val += preds.eq(targets).sum().item()\n",
    "                total_val += targets.size(0)\n",
    "\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_acc_history.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    train_accuracies.append(train_acc_history)\n",
    "    val_accuracies.append(val_acc_history)\n",
    "\n",
    "# 7. 학습 및 검증 정확도 시각화\n",
    "epochs_range = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(k):\n",
    "    plt.plot(epochs_range, train_accuracies[i], label=f'Fold {i+1} Train Acc')\n",
    "    plt.plot(epochs_range, val_accuracies[i], label=f'Fold {i+1} Val Acc', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Validation Accuracy per Fold')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
