[page 1]
안녕하십니까. 저는 이미지 분류 모델의 성능 비교 프로젝트를 발표하게 된 발표자 이종철입니다.

[page 2]
제목에서 말씀드렸듯이 프로젝트의 주제는 이미지 분류인데요.
데이터셋은 다음과 같이 모델의 훈련을 위한 trainset 4000장, testset 4000장이 있고, 각 이미지는 우측의 10개 클래스 중 하나에 해당합니다.
따라서 본 프로젝트의 궁극적인 목적은 딥러닝 모델을 통해 testset 이미지들의 클래스를 잘 예측해내는 것입니다.

[page 3]
이미지 분류 문제를 해결하기 위한 대표적인 딥러닝 모델로는 CNN 기반 모델이 주로 사용되는데요.
본론에 앞서 고전적인 CNN 분류모델의 구조에 대해 설명하겠습니다.
CNN 모델의 입력으로 들어온 이미지는, 합성곱 연산을 수행하는 Convolution layer와 Pooling 과정을 거쳐 특징이 요약된 피쳐맵으로 압축되고, 완전연결층을 지나 각 클래스로 분류됩니다.
딥러닝 분야가 발전하면서 이런 기본 구조에 기반하여 더 정확하고, 효율적인 수많은 응용모델들이 등장하였는데요.

[page 4]
바로 이러한 응용모델간의 분류성능에 어떤 차이가 있는지 알아보는 것이 프로젝트의 첫번째 목표입니다.
저희는 비교를 위해 세 가지 모델을 선택하였는데요. 
CNN 구조를 깊게 쌓은 VGG, 잔차 연결이라는 새로운 방법으로 모델 깊이의 한계를 끌어올린 ResNet, 그리고 모델 확장 방법을 균형있게 사용하여 효율성과 성능을 모두 갖춘 EfficientNet을 비교하기로 하였습니다.

[page 5]
프로젝트의 두번째 목표는 데이터 수를 늘리거나, 증강 기법을 활용하는 등 학습 데이터에 변화를 주는 게 분류 성능에 어떤 영향을 미치는가?를 알아보는 것입니다.
저희는 이를 위해 기존 trainset과 클래스 구성이 같은 CIFAR-10 데이터를 추가로 활용하였고, 다양한 증강방법을 적용해보며, 실험을 통해 분류 성능을 높이고자 하였습니다.

[page 7]
이제 본론으로 들어가서 전체 실험의 흐름부터 설명드리겠습니다.
저희는 훈련에 사용하는 데이터의 변화에 따라 총 네 가지 실험의 결과를 제시할 것입니다.
우선 실험1에서 trainset 4000장만 사용하여 기본 성능을 확인하고
실험2에서는 데이터 수를 증가시키고
실험3에서는 거기에 증강 데이터까지 추가하고
실험4에서는 더 다양한 증강을 적용하면서 에포크를 늘려 충분히 학습시켰습니다.
이후에 실험 결과를 제시하면서 각 실험조건이 분류 성능에 어떤 영향을 주었는지 보여드릴 예정입니다.

[page 8]
실험 결과를 보여드리기 전에 실험에 사용된 모델들의 구조를 살펴보면서 특징을 짚고 넘어가겠습니다.
먼저 VGG19는 16개의 Convolution층, 3개의 완전연결층으로 구성된 모델입니다. 
특징으로는 모델을 깊게 쌓으면서 당시 통상적으로 사용하던 7x7이나 11x11 커널보다 작은 3x3 커널을 사용하여, 효율적인 학습을 가능하게 만들었습니다.

[page 9]
다음으로 ResNet은 레이어의 입력을 다른 레이어의 출력으로 바로 연결하는 skip connection을 통해 모델 깊이의 한계를 극복한 모델입니다.
기존에는 모델이 일정 수준 이상으로 깊어지면 학습 능력이 저하되어 오히려 모델 성능이 떨어지는 degradation이라 불리는 성능 열화 문제가 존재하였는데요.
skip connection을 활용하여 그 사이의 층들이 잔차에 대해서만 학습하도록 함으로써 해당 문제를 크게 완화하였습니다.
ResNet 논문에서는 레이어를 무려 152개까지 쌓았음에도 대규모 데이터셋에서의 좋은 결과를 제시하며, 매우 깊은 아키텍처에서도 제대로 학습이 가능함을 증명하였습니다.
저희는 소규모 데이터셋에서 효율적인 18개의 레이어로 이루어진 ResNet-18 모델을 사용하였습니다.

[page 10]
마지막으로 EfficientNet입니다. 먼저 CNN 모델의 스케일링 즉, 모델을 키우는 방법에 대해 설명드리겠습니다.
통상적으로 사용되는 것은 세가지인데요.
첫번째로 width scailing은 합성곱에 사용하는 필터의 수를 늘려 다양한 특징을 추출할 수 있도록 하는 방법이고,
두번째로 depth scailing은 모델을 더 깊게 쌓아 복잡한 패턴을 학습할 수 있도록 하는 방법입니다. vgg와 resnet은 이 방법에 초점을 두었습니다.
마지막으로 resolution scailing은 입력 이미지의 해상도를 높여 더 세밀한 정보를 학습할 수 있도록 하는 방법인데요.
기존에는 이 셋 중 하나의 방법으로만 모델을 확장한 반면,
EfficientNet에서는 이를 조합한 컴파운드 스케일링을 통해
적은 파라미터로 높은 성능을 내도록 설계되었습니다.

[page 11]
여기선 대부분 일반적인 Convolution 대신 MBConv (모바일 인버티드 보틀넥 컨볼루션)이 사용됩니다.
이 MBConv 층의 특징은 인버티드 보틀넥이라는 이름에서 알 수 있듯이 내부에서 채널의 수를 한번 늘렸다가 다시 줄이는 작업을 수행하는 것인데요.
이 MBConv의 장점을 간단히 말하자면 연산은 적고, 다양한 특징을 학습할 수 있어, 경량화된 모델에 특화된 Convolution 방법입니다.
EfficientNet에선 입력 이미지의 해상도를 늘리는 Resolution 스케일링, MBConv 내의 과정에서 width 스케일링, 전체 층을 깊게 구성하는 depth 스케일링을 모두 사용하였습니다.
EfficientNet은 이런 구조를 통해 모델의 효율성과 성능을 균형있게 개선할 수 있었습니다.

[page 12]
이제 앞의 모델들을 다양한 조건에서 비교하는 과정을 설명드리겠습니다.
실험의 기본 설정은 다음과 같고요. Accuracy를 측정하기 위해 데이터의 20%를 층화추출하여 validation set으로 활용했습니다.
첫번째 실험에선 4000장의 데이터만으로 모델별 기본 성능을 확인하였습니다.
각각 ~ 로 성능이 저조하게 나타났으며, ResNet의 기본 성능이 가장 높았습니다.

[page 13]
두번째 실험에서는 학습 이미지 수에 따른 성능 변화를 보기 위해
CIFAR-10의 이미지 50000장을 함께 학습하였는데요.

[page 14]
그 결과 저조했던 성능이 

[page 15]
다음과 같이 성능이 크게 향상되었습니다.
기본 성능이 가장 낮았던 VGG의 상승폭이 가장 컸고,
ResNet보다 기본 성능이 낮았던 EfficientNet의 성능이 가장 좋았습니다.
실험2를 통해 단순히 학습 데이터를 늘리는 것만으로도 모델의 일반화 성능에 큰 도움이 됨을 알 수 있습니다.

[page 16]
세번째 실험에서는 데이터 증강의 효과를 보기 위해 CIFAR-10 데이터의 일부 이미지에 증강을 적용하여 학습 데이터에 추가하였습니다.
데이터 증강은 기존 데이터에 여러가지 변형을 준 데이터를 활용하여 모델의 일반화 성능을 높이고, 학습 데이터 수를 늘리는 방법입니다.
증강 방법에 따라 각도, 크기, 색상 등 다양한 요소에 무작위한 변형을 주어 새로운 이미지처럼 학습에 사용할 수 있습니다.

[page 17]
저희는 실험 3,4에서 총 네가지 증강 방법을 사용하였습니다. 네가지 방법은 왼쪽부터 순서대로 뒤집고, 자르고, 회전시키고, 대비와 밝기를 조절하는 방법입니다.

[page 18]
증강을 처음 적용한 실험3에서는 원본 이미지의 특성을 해치지 않도록 단순하게 이미지 회전과 뒤집기만을 사용하였고,

[page 19]
증강 이미지 15000장을 포함해서 총 69000장을 학습시켰습니다.
그 결과 VGG 모델의 성능이 감소하긴 했으나, 나머지 모델들은 증강 데이터를 추가함으로써 성능이 소폭 향상되었습니다.

[page 20]
실험3에서 저희는 데이터 증강이 성능 향상에 도움이 될 수 있단걸 확인했고, 더 다양한 증강 방법을 적용하고자 시도하였는데요.
먼저 여러 증강 방법을 한번에 적용하여 증강 이미지를 생성하는 방법을 실험하였으나, 오히려 성능이 하락하였습니다.
다음으로는 증강 이미지 수를 두배로 늘려보았으나 마찬가지로 성능이 향상되지 않았습니다.
저희는 그 문제의 해결방안을 데이터에서 추측하였는데요.
저희가 원인에 대해 세운 가설은 원본 이미지가 이미 저화질이기 때문에 
같은 이미지에 여러 증강 방법이 중첩되면 특징이 많이 손실돼서 예측에 악영향을 준다는 것입니다.
실험 4에서는 이를 고려하면서 증강 방법을 다양화했을 때의 변화를 관찰하고자 하였습니다.

[page 21]
따라서 다양한 증강을 적용하면서도 원본 이미지의 특징을 최대한 유지하기 위해 증강 방법을 두가지 조합으로 나누어서 적용하였습니다.
첫번째 조합은 뒤집기와 자르기이고요. 

[page 22]
두번째 조합은 뒤집기, 회전, 그리고 밝기 및 대비 조절입니다.

[page 23]
저희는 이 두가지 조합을 적용한 증강 이미지를 각각 15000장씩 사용하여, 총 84000장으로 학습을 진행하였고요.
학습 난이도가 증가하였다고 생각하여 실험적으로 에폭을 조정하여 60까지 늘렸습니다.

[page 24]
그 결과 증강을 단순하게 적용했을 때에 비해서

[page 25]
세 모델 모두 상당히 큰 폭의 성능향상을 보여주었고, 
특히 Efficientnet은 94%를 넘는 최고 성능을 기록하였습니다.

[page 26]
최종적으로 네가지 실험을 진행한 결과를 요약하며, 그를 통해 얻을 수 있는 결론을 말씀드리겠습니다.

[page 27]
마지막으로 실험별 성능을 비교한 것인데요.
붉은 색 글씨는 각 실험별 최고 성능을 표시한 것입니다.
모든 실험에서 VGG에 비해 이후에 나온 EfficientNet과 ResNet의 성능이 우수했으며, 세 모델 모두 실험4에서의 결과가 가장 좋았습니다.

[page 28]
또한 프로젝트 전체의 최고 성능은 EfficientNet의 실험4 결과였습니다.
저희는 본 프로젝트를 통해 학습 데이터 수를 늘리고, 다양한 증강방법을 잘 사용할수록, 일반화성능에 도움이 되며,
모델 중에는 EfficientNet이 가장 좋은 분류성능을 보인다는 결론을 도출할 수 있었습니다.

[page 29]
팀프로젝트를 하면서 느낀 각자의 소감을 보여드리며, 발표 마치겠습니다.